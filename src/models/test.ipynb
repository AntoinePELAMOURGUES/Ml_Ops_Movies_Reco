{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from surprise import Reader, Dataset, accuracy, SVD\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "def read_ratings(ratings_csv: str, data_dir: str = \"/home/antoine/Ml_Ops_Movies_Reco/src/data/data/raw\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lit le fichier CSV contenant les évaluations des films.\n",
    "\n",
    "    :param ratings_csv: Nom du fichier CSV contenant les évaluations.\n",
    "    :param data_dir: Répertoire où se trouve le fichier CSV.\n",
    "    :return: DataFrame contenant les évaluations.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(os.path.join(data_dir, ratings_csv))\n",
    "    print(\"Dataset ratings chargé\")\n",
    "    return data\n",
    "\n",
    "def read_movies(movies_csv: str, data_dir: str = \"/home/antoine/Ml_Ops_Movies_Reco/src/data/data/raw\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lit le fichier CSV contenant les informations sur les films.\n",
    "\n",
    "    :param movies_csv: Nom du fichier CSV contenant les informations sur les films.\n",
    "    :param data_dir: Répertoire où se trouve le fichier CSV.\n",
    "    :return: DataFrame contenant les informations sur les films.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(os.path.join(data_dir, movies_csv))\n",
    "    print(\"Dataset movies chargé\")\n",
    "    return df\n",
    "\n",
    "def create_user_matrix(ratings: pd.DataFrame, movies: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crée une matrice utilisateur à partir des évaluations et des informations sur les films.\n",
    "\n",
    "    :param ratings: DataFrame contenant les évaluations.\n",
    "    :param movies: DataFrame contenant les informations sur les films.\n",
    "    :return: DataFrame fusionné et prétraité.\n",
    "    \"\"\"\n",
    "    user_encoder = LabelEncoder()\n",
    "    movie_encoder = LabelEncoder()\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    # Fusionner les évaluations et les informations sur les films\n",
    "    df = ratings.merge(movies[['movieId', 'genres']], on=\"movieId\", how=\"left\")\n",
    "    df['userId'] = user_encoder.fit_transform(df['userId'])\n",
    "    df['movieId'] = movie_encoder.fit_transform(df['movieId'])\n",
    "\n",
    "    # Traitement des genres\n",
    "    df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('genres').str.split('|')),\n",
    "                               columns=mlb.classes_, index=df.index))\n",
    "    df = df.drop(\"(no genres listed)\", axis=1, errors='ignore')  # Ignore si la colonne n'existe pas\n",
    "\n",
    "    print(\"Dataset fusionnés et prétraités\")\n",
    "    return df\n",
    "\n",
    "def cross_validation_model(df: pd.DataFrame):\n",
    "\n",
    "    # A reader is still needed but only the rating_scale param is required.\n",
    "    reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "    algo = SVD()\n",
    "\n",
    "    # Run 5-fold cross-validation and print results\n",
    "    cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)\n",
    "\n",
    "    return algo\n",
    "\n",
    "def train_model(df: pd.DataFrame, model: SVD = SVD()) -> SVD:\n",
    "    \"\"\"\n",
    "    Entraîne le modèle de recommandation sur les données fournies.\n",
    "\n",
    "    :param df: DataFrame contenant les données d'entraînement.\n",
    "    :param model: Modèle de recommandation à entraîner (par défaut SVD).\n",
    "    :return: Modèle entraîné.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    reader = Reader(rating_scale=(0.5, 5))\n",
    "    data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader=reader)\n",
    "    trainset, testset = train_test_split(data, test_size=0.4)\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    model.fit(trainset)\n",
    "\n",
    "    # Évaluer le modèle\n",
    "    predictions = model.predict(testset)\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    mae = accuracy.mae(predictions)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Score RMSE : {rmse}\")\n",
    "    print(f\"Score MAE : {mae}\")\n",
    "    print(f\"Temps d'exécution: {end - start} secondes\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_model(model: SVD, filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Sauvegarde le modèle entraîné dans un fichier.\n",
    "\n",
    "    :param model: Modèle à sauvegarder.\n",
    "    :param filepath: Chemin complet du fichier où le modèle sera sauvegardé.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)  # Créer le dossier si nécessaire\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        print(f'Modèle sauvegardé sous {filepath}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ratings chargé\n",
      "Dataset movies chargé\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "\n",
    "# Chargement des données\n",
    "ratings = read_ratings('ratings.csv')\n",
    "movies = read_movies('movies.csv')\n",
    "\n",
    "# Création de la matrice utilisateur\n",
    "df = create_user_matrix(ratings, movies)\n",
    "\n",
    "# crossval du modèle\n",
    "model = cross_validation_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, '/home/antoine/Ml_Ops_Movies_Reco/models/model_svd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco_movies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
